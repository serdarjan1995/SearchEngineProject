###The following code parses a list of urls, classifies if the item is img,html,pdf and parses it with ocr or beatiful soup depending on the type.

%pip install pymysql
%pip install pytesseract
%pip install pdf2image
%pip install pdfminer.six

import os
import requests
import mimetypes
import pytesseract
from PIL import Image
from bs4 import BeautifulSoup
from pdf2image import convert_from_bytes
from io import BytesIO
from pdfminer.high_level import extract_text

# Your list of URLs
url_list = pivot_df['url']

def get_mimetype(url, response):
    mime = mimetypes.guess_type(url)[0]
    if not mime and 'Content-Type' in response.headers:
        mime = response.headers['Content-Type'].split(';')[0]
    return mime

def extract_html_text(html):
    soup = BeautifulSoup(html, 'html.parser')
    return soup.get_text(separator=' ', strip=True)

def ocr_image(content):
    img = Image.open(BytesIO(content))
    return pytesseract.image_to_string(img)

def ocr_pdf(content):
    try:
        text = extract_text(BytesIO(content))
        if text.strip():
            return text
    except Exception:
        pass
    images = convert_from_bytes(content)
    return "\n".join(pytesseract.image_to_string(img) for img in images)

def process_url(url):
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36",
            "Accept-Language": "en-US,en;q=0.9",
        }
        response = requests.get(url, headers=headers, timeout=20)
        mime = get_mimetype(url, response)

        if mime is None:
            return {'url': url, 'success': False, 'info_type': 'unknown', 'text': ''}

        if mime.startswith('text/html'):
            text = extract_html_text(response.text)
            return {'url': url, 'success': bool(text.strip()), 'info_type': 'html', 'text': text}

        elif mime == 'application/pdf':
            text = ocr_pdf(response.content)
            return {'url': url, 'success': bool(text.strip()), 'info_type': 'pdf', 'text': text}

        elif mime.startswith('image/'):
            text = ocr_image(response.content)
            return {'url': url, 'success': bool(text.strip()), 'info_type': 'image', 'text': text}

        else:
            return {'url': url, 'success': False, 'info_type': 'unsupported', 'text': ''}

    except Exception as e:
        print(f"Error processing {url}: {e}")
        return {'url': url, 'success': False, 'info_type': 'error', 'text': ''}

# Run and collect results
results = [process_url(url) for url in url_list]

results_df = pd.DataFrame(results)
results_df
