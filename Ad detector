##This file has code to detect ads and duplicates. Then it is applied to a dataframe called df_merged

%pip install adblockparser

from adblockparser import AdblockRules
from urllib.parse import urlparse, parse_qs
import pandas as pd

# Load EasyList rules
with open("easylist.txt", encoding="utf-8") as f:
    raw_rules = f.readlines()

rules = AdblockRules(raw_rules)

# Your own heuristics
AD_DOMAINS = [
    "doubleclick.net", "googlesyndication.com", "googleadservices.com",
    "bing.com/aclick", "yahoo.com/ads", "duckduckgo.com/y.js",
    "adservice", "adsystem", "sponsored", "promo", "affiliate"
]

AD_QUERY_PARAMS = {"utm_source", "utm_campaign", "gclid", "fbclid", "clickid", "ref", "affid", "adid", "track"}

def is_ad_heuristic(url):
    parsed = urlparse(url)
    if any(domain in parsed.netloc.lower() for domain in AD_DOMAINS):
        return True
    if any(keyword in parsed.path.lower() for keyword in AD_DOMAINS):
        return True
    query_params = parse_qs(parsed.query)
    if AD_QUERY_PARAMS & set(query_params.keys()):
        return True
    return False

def is_ad_url(url):
    return rules.should_block(url) or is_ad_heuristic(url)


df_merged['is_ad'] = df_merged['url'].apply(is_ad_url)

###Finding duplicates

df_merged['is_duplicate'] = df_merged.duplicated(subset='url', keep=False)
df_merged.head()
